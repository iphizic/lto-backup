#!/usr/bin/env python3
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ —Ü–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç–∏ —Ñ–∞–π–ª–æ–≤ LTO Backup System
–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∫–æ–Ω—Ç—Ä–æ–ª—å–Ω—ã–µ —Å—É–º–º—ã, –Ω–∞–ª–∏—á–∏–µ —Ñ–∞–π–ª–æ–≤ –∏ –∏—Ö –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å
"""

import os
import sys
import hashlib
import json
from pathlib import Path
from datetime import datetime
import yaml

def calculate_file_hash(filepath, algorithm='sha256'):
    """–í—ã—á–∏—Å–ª–µ–Ω–∏–µ —Ö—ç—à–∞ —Ñ–∞–π–ª–∞"""
    if not os.path.exists(filepath):
        return None
    
    hash_func = getattr(hashlib, algorithm)()
    
    try:
        with open(filepath, 'rb') as f:
            # –ß–∏—Ç–∞–µ–º —Ñ–∞–π–ª –±–ª–æ–∫–∞–º–∏ –¥–ª—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏
            for block in iter(lambda: f.read(65536), b''):
                hash_func.update(block)
        return hash_func.hexdigest()
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–∞ {filepath}: {e}")
        return None

def verify_python_module(module_path):
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç–∏ Python –º–æ–¥—É–ª—è"""
    if not os.path.exists(module_path):
        return False, f"–§–∞–π–ª –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç: {module_path}"
    
    try:
        # –ü—ã—Ç–∞–µ–º—Å—è –≤—ã–ø–æ–ª–Ω–∏—Ç—å —Å–∏–Ω—Ç–∞–∫—Å–∏—á–µ—Å–∫—É—é –ø—Ä–æ–≤–µ—Ä–∫—É
        with open(module_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –±–∞–∑–æ–≤—ã–π —Å–∏–Ω—Ç–∞–∫—Å–∏—Å
        compile(content, module_path, 'exec')
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∏–º–ø–æ—Ä—Ç–æ–≤ (–µ—Å–ª–∏ –Ω—É–∂–Ω–æ)
        if 'import ' in content or 'from ' in content:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –∏–º–ø–æ—Ä—Ç—ã –Ω–∞ —Å–≤–æ–∏—Ö –º–µ—Å—Ç–∞—Ö
            lines = content.split('\n')
            imports_found = False
            for line in lines:
                stripped = line.strip()
                if stripped.startswith('import ') or stripped.startswith('from '):
                    imports_found = True
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–∏–Ω—Ç–∞–∫—Å–∏—Å –∏–º–ø–æ—Ä—Ç–∞
                    try:
                        compile(stripped, '<string>', 'exec')
                    except SyntaxError as e:
                        return False, f"–°–∏–Ω—Ç–∞–∫—Å–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –≤ –∏–º–ø–æ—Ä—Ç–µ: {e}"
            
            if imports_found and 'sys.path' in content:
                return True, "‚úÖ –ú–æ–¥—É–ª—å –∫–æ—Ä—Ä–µ–∫—Ç–µ–Ω"
        
        return True, "‚úÖ –ú–æ–¥—É–ª—å –∫–æ—Ä—Ä–µ–∫—Ç–µ–Ω"
        
    except SyntaxError as e:
        return False, f"–°–∏–Ω—Ç–∞–∫—Å–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}"
    except Exception as e:
        return False, f"–û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ –º–æ–¥—É–ª—è: {e}"

def verify_yaml_config(config_path):
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç–∏ YAML –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏"""
    if not os.path.exists(config_path):
        return False, f"–§–∞–π–ª –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç: {config_path}"
    
    try:
        with open(config_path, 'r', encoding='utf-8') as f:
            config = yaml.safe_load(f)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ —Å–µ–∫—Ü–∏–∏
        required_sections = ['database', 'hardware', 'buffer']
        for section in required_sections:
            if section not in config:
                return False, f"–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–∞—è —Å–µ–∫—Ü–∏—è: {section}"
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –ø–æ–ª—è
        required_fields = {
            'database': ['registry_file', 'manifest_dir'],
            'hardware': ['tape_device', 'robot_enabled'],
            'buffer': ['size', 'fill_percent', 'block_size']
        }
        
        for section, fields in required_fields.items():
            for field in fields:
                if field not in config.get(section, {}):
                    return False, f"–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –ø–æ–ª–µ {section}.{field}"
        
        return True, "‚úÖ –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è YAML –∫–æ—Ä—Ä–µ–∫—Ç–Ω–∞"
        
    except yaml.YAMLError as e:
        return False, f"–û—à–∏–±–∫–∞ YAML: {e}"
    except Exception as e:
        return False, f"–û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏: {e}"

def verify_directory_structure(base_dir='.'):
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π"""
    required_dirs = [
        'modules',
        'scripts',
        'logs',
        'manifests',
        'backups'
    ]
    
    issues = []
    for dir_name in required_dirs:
        dir_path = os.path.join(base_dir, dir_name)
        if not os.path.exists(dir_path):
            issues.append(f"‚ùå –û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è: {dir_name}")
        elif not os.path.isdir(dir_path):
            issues.append(f"‚ùå –ù–µ —è–≤–ª—è–µ—Ç—Å—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–µ–π: {dir_name}")
        else:
            print(f"‚úÖ –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è {dir_name} —Å—É—â–µ—Å—Ç–≤—É–µ—Ç")
    
    return len(issues) == 0, issues

def get_file_checksums(directory='.', extensions=None):
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –∫–æ–Ω—Ç—Ä–æ–ª—å–Ω—ã—Ö —Å—É–º–º –≤—Å–µ—Ö —Ñ–∞–π–ª–æ–≤"""
    if extensions is None:
        extensions = ['.py', '.yaml', '.yml', '.json', '.md', '.sh']
    
    checksums = {}
    
    for root, dirs, files in os.walk(directory):
        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –Ω–µ–∫–æ—Ç–æ—Ä—ã–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
        skip_dirs = ['.git', '__pycache__', '.pytest_cache', 'venv', 'env']
        dirs[:] = [d for d in dirs if d not in skip_dirs]
        
        for file in files:
            if any(file.endswith(ext) for ext in extensions):
                filepath = os.path.join(root, file)
                rel_path = os.path.relpath(filepath, directory)
                file_hash = calculate_file_hash(filepath)
                
                if file_hash:
                    checksums[rel_path] = {
                        'hash': file_hash,
                        'size': os.path.getsize(filepath),
                        'modified': os.path.getmtime(filepath)
                    }
    
    return checksums

def generate_integrity_report(base_dir='.'):
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø–æ–ª–Ω–æ–≥–æ –æ—Ç—á–µ—Ç–∞ –æ —Ü–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç–∏ —Å–∏—Å—Ç–µ–º—ã"""
    print("üîç –ì–ï–ù–ï–†–ê–¶–ò–Ø –û–¢–ß–ï–¢–ê –û –¶–ï–õ–û–°–¢–ù–û–°–¢–ò LTO BACKUP SYSTEM")
    print("=" * 80)
    
    report = {
        'timestamp': datetime.now().isoformat(),
        'base_directory': os.path.abspath(base_dir),
        'files': {},
        'issues': [],
        'summary': {}
    }
    
    # 1. –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π
    print("\n1. üìÅ –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π...")
    dirs_ok, dir_issues = verify_directory_structure(base_dir)
    if not dirs_ok:
        report['issues'].extend(dir_issues)
        for issue in dir_issues:
            print(f"   {issue}")
    else:
        print("   ‚úÖ –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π –∫–æ—Ä—Ä–µ–∫—Ç–Ω–∞")
    
    # 2. –ü—Ä–æ–≤–µ—Ä–∫–∞ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
    print("\n2. üìã –ü—Ä–æ–≤–µ—Ä–∫–∞ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤...")
    required_files = [
        ('lto_main.py', 'main'),
        ('config.yaml', 'config'),
        ('modules/__init__.py', 'module'),
        ('modules/config_manager.py', 'module'),
        ('modules/file_utils.py', 'module'),
        ('modules/system_monitor.py', 'module'),
        ('modules/tape_drive.py', 'module'),
        ('modules/backup_job.py', 'module'),
        ('modules/lto_logger.py', 'module'),
        ('modules/registry_manager.py', 'module'),
        ('modules/core_tg.py', 'module'),
        ('scripts/log_manager.py', 'script'),
        ('scripts/setup_security.py', 'script'),
        ('scripts/test_logging.py', 'script'),
        ('scripts/check_deps.sh', 'script'),
        ('README.md', 'doc')
    ]
    
    missing_files = []
    for file_path, file_type in required_files:
        full_path = os.path.join(base_dir, file_path)
        if not os.path.exists(full_path):
            missing_files.append(file_path)
            print(f"   ‚ùå –û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç: {file_path}")
        else:
            print(f"   ‚úÖ –ü—Ä–∏—Å—É—Ç—Å—Ç–≤—É–µ—Ç: {file_path}")
    
    if missing_files:
        report['issues'].append(f"–û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç —Ñ–∞–π–ª—ã: {', '.join(missing_files)}")
    
    # 3. –ü—Ä–æ–≤–µ—Ä–∫–∞ Python –º–æ–¥—É–ª–µ–π
    print("\n3. üêç –ü—Ä–æ–≤–µ—Ä–∫–∞ Python –º–æ–¥—É–ª–µ–π...")
    python_files = []
    for root, dirs, files in os.walk(base_dir):
        for file in files:
            if file.endswith('.py'):
                python_files.append(os.path.join(root, file))
    
    python_issues = []
    for py_file in python_files[:20]:  # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–µ—Ä–≤—ã–µ 20 —Ñ–∞–π–ª–æ–≤ –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏
        rel_path = os.path.relpath(py_file, base_dir)
        is_ok, message = verify_python_module(py_file)
        if not is_ok:
            python_issues.append(f"{rel_path}: {message}")
            print(f"   ‚ùå {rel_path}: {message}")
        else:
            print(f"   ‚úÖ {rel_path} –∫–æ—Ä—Ä–µ–∫—Ç–µ–Ω")
    
    if python_issues:
        report['issues'].extend(python_issues)
    
    # 4. –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
    print("\n4. ‚öôÔ∏è –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏...")
    config_path = os.path.join(base_dir, 'config.yaml')
    if os.path.exists(config_path):
        is_ok, message = verify_yaml_config(config_path)
        if not is_ok:
            report['issues'].append(f"–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è: {message}")
            print(f"   ‚ùå {message}")
        else:
            print(f"   ‚úÖ {message}")
    else:
        report['issues'].append("–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç config.yaml")
        print("   ‚ùå –û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç config.yaml")
    
    # 5. –í—ã—á–∏—Å–ª–µ–Ω–∏–µ –∫–æ–Ω—Ç—Ä–æ–ª—å–Ω—ã—Ö —Å—É–º–º
    print("\n5. üî¢ –í—ã—á–∏—Å–ª–µ–Ω–∏–µ –∫–æ–Ω—Ç—Ä–æ–ª—å–Ω—ã—Ö —Å—É–º–º...")
    checksums = get_file_checksums(base_dir)
    report['files'] = checksums
    
    # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ —Ç–∏–ø–∞–º —Ñ–∞–π–ª–æ–≤
    file_types = {}
    for file_path, info in checksums.items():
        ext = os.path.splitext(file_path)[1].lower()
        file_types.setdefault(ext, []).append(file_path)
    
    print(f"   –ù–∞–π–¥–µ–Ω–æ —Ñ–∞–π–ª–æ–≤: {len(checksums)}")
    for ext, files in file_types.items():
        print(f"   {ext}: {len(files)} —Ñ–∞–π–ª–æ–≤")
    
    # 6. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ—Ç—á–µ—Ç–∞
    print("\n6. üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ—Ç—á–µ—Ç–∞...")
    report_path = os.path.join(base_dir, 'integrity_report.json')
    
    with open(report_path, 'w', encoding='utf-8') as f:
        json.dump(report, f, indent=2, ensure_ascii=False)
    
    print(f"   ‚úÖ –û—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {report_path}")
    
    # 7. –ò—Ç–æ–≥–æ–≤–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    print("\n7. üìä –ò—Ç–æ–≥–æ–≤–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
    total_issues = len(report['issues'])
    
    report['summary'] = {
        'total_files': len(checksums),
        'total_issues': total_issues,
        'timestamp': datetime.now().isoformat(),
        'file_types': {ext: len(files) for ext, files in file_types.items()}
    }
    
    if total_issues == 0:
        print("   üéâ –í–°–ï –ü–†–û–í–ï–†–ö–ò –ü–†–û–ô–î–ï–ù–´ –£–°–ü–ï–®–ù–û!")
        print("   –°–∏—Å—Ç–µ–º–∞ —Ü–µ–ª–æ—Å—Ç–Ω–∞ –∏ –≥–æ—Ç–æ–≤–∞ –∫ —Ä–∞–±–æ—Ç–µ.")
    else:
        print(f"   ‚ö†Ô∏è  –û–±–Ω–∞—Ä—É–∂–µ–Ω–æ –ø—Ä–æ–±–ª–µ–º: {total_issues}")
        print("   –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –∏—Å–ø—Ä–∞–≤—å—Ç–µ —É–∫–∞–∑–∞–Ω–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã –ø–µ—Ä–µ–¥ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º.")
    
    print("\n" + "=" * 80)
    return report

def compare_checksums(report1_path, report2_path):
    """–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –¥–≤—É—Ö –æ—Ç—á–µ—Ç–æ–≤ –æ –∫–æ–Ω—Ç—Ä–æ–ª—å–Ω—ã—Ö —Å—É–º–º–∞—Ö"""
    print("üîÑ –°–†–ê–í–ù–ï–ù–ò–ï –ö–û–ù–¢–†–û–õ–¨–ù–´–• –°–£–ú–ú")
    print("=" * 80)
    
    with open(report1_path, 'r', encoding='utf-8') as f:
        report1 = json.load(f)
    
    with open(report2_path, 'r', encoding='utf-8') as f:
        report2 = json.load(f)
    
    files1 = set(report1['files'].keys())
    files2 = set(report2['files'].keys())
    
    # –§–∞–π–ª—ã —Ç–æ–ª—å–∫–æ –≤ –ø–µ—Ä–≤–æ–º –æ—Ç—á–µ—Ç–µ
    only_in_1 = files1 - files2
    # –§–∞–π–ª—ã —Ç–æ–ª—å–∫–æ –≤–æ –≤—Ç–æ—Ä–æ–º –æ—Ç—á–µ—Ç–µ
    only_in_2 = files2 - files1
    # –û–±—â–∏–µ —Ñ–∞–π–ª—ã
    common_files = files1 & files2
    
    print(f"\nüìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è:")
    print(f"   –§–∞–π–ª–æ–≤ –≤ –æ—Ç—á–µ—Ç–µ 1: {len(files1)}")
    print(f"   –§–∞–π–ª–æ–≤ –≤ –æ—Ç—á–µ—Ç–µ 2: {len(files2)}")
    print(f"   –û–±—â–∏—Ö —Ñ–∞–π–ª–æ–≤: {len(common_files)}")
    
    if only_in_1:
        print(f"\nüìÑ –§–∞–π–ª—ã —Ç–æ–ª—å–∫–æ –≤ –æ—Ç—á–µ—Ç–µ 1 ({len(only_in_1)}):")
        for file in sorted(only_in_1)[:10]:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 10
            print(f"   + {file}")
        if len(only_in_1) > 10:
            print(f"   ... –∏ –µ—â–µ {len(only_in_1) - 10} —Ñ–∞–π–ª–æ–≤")
    
    if only_in_2:
        print(f"\nüìÑ –§–∞–π–ª—ã —Ç–æ–ª—å–∫–æ –≤ –æ—Ç—á–µ—Ç–µ 2 ({len(only_in_2)}):")
        for file in sorted(only_in_2)[:10]:
            print(f"   - {file}")
        if len(only_in_2) > 10:
            print(f"   ... –∏ –µ—â–µ {len(only_in_2) - 10} —Ñ–∞–π–ª–æ–≤")
    
    # –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –∫–æ–Ω—Ç—Ä–æ–ª—å–Ω—ã—Ö —Å—É–º–º –æ–±—â–∏—Ö —Ñ–∞–π–ª–æ–≤
    print(f"\nüîç –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –∫–æ–Ω—Ç—Ä–æ–ª—å–Ω—ã—Ö —Å—É–º–º –æ–±—â–∏—Ö —Ñ–∞–π–ª–æ–≤:")
    different_hashes = []
    
    for file in sorted(common_files):
        hash1 = report1['files'][file]['hash']
        hash2 = report2['files'][file]['hash']
        
        if hash1 != hash2:
            different_hashes.append(file)
    
    if different_hashes:
        print(f"   ‚ö†Ô∏è  –§–∞–π–ª–æ–≤ —Å —Ä–∞–∑–Ω—ã–º–∏ —Ö—ç—à–∞–º–∏: {len(different_hashes)}")
        for file in different_hashes[:5]:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 5
            print(f"   ‚úó {file}")
        if len(different_hashes) > 5:
            print(f"   ... –∏ –µ—â–µ {len(different_hashes) - 5} —Ñ–∞–π–ª–æ–≤")
    else:
        print("   ‚úÖ –í—Å–µ –æ–±—â–∏–µ —Ñ–∞–π–ª—ã –∏–¥–µ–Ω—Ç–∏—á–Ω—ã")
    
    return {
        'only_in_1': list(only_in_1),
        'only_in_2': list(only_in_2),
        'different_hashes': different_hashes,
        'common_files_count': len(common_files)
    }

def create_reference_checksums(base_dir='.'):
    """–°–æ–∑–¥–∞–Ω–∏–µ —ç—Ç–∞–ª–æ–Ω–Ω—ã—Ö –∫–æ–Ω—Ç—Ä–æ–ª—å–Ω—ã—Ö —Å—É–º–º –¥–ª—è —Å–∏—Å—Ç–µ–º—ã"""
    print("üèóÔ∏è –°–û–ó–î–ê–ù–ò–ï –≠–¢–ê–õ–û–ù–ù–´–• –ö–û–ù–¢–†–û–õ–¨–ù–´–• –°–£–ú–ú")
    print("=" * 80)
    
    # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ —Ñ–∞–π–ª—ã
    checksums = get_file_checksums(base_dir)
    
    # –°–æ–∑–¥–∞–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –æ—Ç—á–µ—Ç
    reference = {
        'system': 'LTO Backup System',
        'version': '2.0.0',
        'timestamp': datetime.now().isoformat(),
        'created_by': 'Integrity Check Script',
        'files': {}
    }
    
    # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º —Ñ–∞–π–ª—ã –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
    categories = {
        'core': ['lto_main.py', 'config.yaml', 'README.md'],
        'modules': ['modules/'],
        'scripts': ['scripts/'],
        'documentation': ['docs/', '*.md']
    }
    
    for file_path, info in checksums.items():
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏—é
        category = 'other'
        for cat_name, patterns in categories.items():
            for pattern in patterns:
                if pattern.endswith('/'):
                    if file_path.startswith(pattern):
                        category = cat_name
                        break
                elif file_path == pattern:
                    category = cat_name
                    break
        
        reference['files'][file_path] = {
            'hash': info['hash'],
            'size': info['size'],
            'category': category,
            'algorithm': 'sha256'
        }
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —ç—Ç–∞–ª–æ–Ω–Ω—ã–π —Ñ–∞–π–ª
    ref_path = os.path.join(base_dir, 'reference_checksums.json')
    with open(ref_path, 'w', encoding='utf-8') as f:
        json.dump(reference, f, indent=2, ensure_ascii=False)
    
    print(f"‚úÖ –≠—Ç–∞–ª–æ–Ω–Ω—ã–µ –∫–æ–Ω—Ç—Ä–æ–ª—å–Ω—ã–µ —Å—É–º–º—ã —Å–æ–∑–¥–∞–Ω—ã: {ref_path}")
    print(f"üìä –í—Å–µ–≥–æ —Ñ–∞–π–ª–æ–≤: {len(checksums)}")
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
    category_stats = {}
    for file_info in reference['files'].values():
        cat = file_info['category']
        category_stats[cat] = category_stats.get(cat, 0) + 1
    
    print("\nüìÅ –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º:")
    for cat, count in sorted(category_stats.items()):
        print(f"   {cat}: {count} —Ñ–∞–π–ª–æ–≤")
    
    return reference

def verify_against_reference(base_dir='.', reference_path=None):
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–∏—Å—Ç–µ–º—ã –ø—Ä–æ—Ç–∏–≤ —ç—Ç–∞–ª–æ–Ω–Ω—ã—Ö –∫–æ–Ω—Ç—Ä–æ–ª—å–Ω—ã—Ö —Å—É–º–º"""
    if reference_path is None:
        reference_path = os.path.join(base_dir, 'reference_checksums.json')
    
    if not os.path.exists(reference_path):
        print(f"‚ùå –≠—Ç–∞–ª–æ–Ω–Ω—ã–π —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {reference_path}")
        print("   –°–Ω–∞—á–∞–ª–∞ —Å–æ–∑–¥–∞–π—Ç–µ —ç—Ç–∞–ª–æ–Ω–Ω—ã–µ –∫–æ–Ω—Ç—Ä–æ–ª—å–Ω—ã–µ —Å—É–º–º—ã.")
        return False
    
    print("üîç –ü–†–û–í–ï–†–ö–ê –°–ò–°–¢–ï–ú–´ –ü–û –≠–¢–ê–õ–û–ù–£")
    print("=" * 80)
    
    with open(reference_path, 'r', encoding='utf-8') as f:
        reference = json.load(f)
    
    # –ü–æ–ª—É—á–∞–µ–º —Ç–µ–∫—É—â–∏–µ –∫–æ–Ω—Ç—Ä–æ–ª—å–Ω—ã–µ —Å—É–º–º—ã
    current_checksums = get_file_checksums(base_dir)
    
    # –°—Ä–∞–≤–Ω–∏–≤–∞–µ–º
    reference_files = set(reference['files'].keys())
    current_files = set(current_checksums.keys())
    
    missing_files = reference_files - current_files
    extra_files = current_files - reference_files
    common_files = reference_files & current_files
    
    issues = []
    
    print(f"\nüìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏:")
    print(f"   –û–∂–∏–¥–∞–µ—Ç—Å—è —Ñ–∞–π–ª–æ–≤: {len(reference_files)}")
    print(f"   –ù–∞–π–¥–µ–Ω–æ —Ñ–∞–π–ª–æ–≤: {len(current_files)}")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ —Ñ–∞–π–ª—ã
    if missing_files:
        print(f"\n‚ùå –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ —Ñ–∞–π–ª—ã ({len(missing_files)}):")
        for file in sorted(missing_files)[:10]:
            print(f"   - {file}")
            issues.append(f"–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç —Ñ–∞–π–ª: {file}")
        if len(missing_files) > 10:
            print(f"   ... –∏ –µ—â–µ {len(missing_files) - 10} —Ñ–∞–π–ª–æ–≤")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ª–∏—à–Ω–∏–µ —Ñ–∞–π–ª—ã
    if extra_files:
        print(f"\n‚ö†Ô∏è  –õ–∏—à–Ω–∏–µ —Ñ–∞–π–ª—ã ({len(extra_files)}):")
        for file in sorted(extra_files)[:10]:
            print(f"   + {file}")
        if len(extra_files) > 10:
            print(f"   ... –∏ –µ—â–µ {len(extra_files) - 10} —Ñ–∞–π–ª–æ–≤")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ–Ω—Ç—Ä–æ–ª—å–Ω—ã–µ —Å—É–º–º—ã –æ–±—â–∏—Ö —Ñ–∞–π–ª–æ–≤
    print(f"\nüî¢ –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ–Ω—Ç—Ä–æ–ª—å–Ω—ã—Ö —Å—É–º–º ({len(common_files)} —Ñ–∞–π–ª–æ–≤):")
    mismatched = []
    
    for file in sorted(common_files):
        ref_hash = reference['files'][file]['hash']
        curr_hash = current_checksums[file]['hash']
        
        if ref_hash != curr_hash:
            mismatched.append(file)
    
    if mismatched:
        print(f"‚ùå –§–∞–π–ª–æ–≤ —Å –Ω–µ—Å–æ–≤–ø–∞–¥–∞—é—â–∏–º–∏ —Ö—ç—à–∞–º–∏: {len(mismatched)}")
        for file in mismatched[:5]:
            print(f"   ‚úó {file}")
            issues.append(f"–ò–∑–º–µ–Ω–µ–Ω —Ñ–∞–π–ª: {file}")
        if len(mismatched) > 5:
            print(f"   ... –∏ –µ—â–µ {len(mismatched) - 5} —Ñ–∞–π–ª–æ–≤")
    else:
        print("   ‚úÖ –í—Å–µ –∫–æ–Ω—Ç—Ä–æ–ª—å–Ω—ã–µ —Å—É–º–º—ã —Å–æ–≤–ø–∞–¥–∞—é—Ç")
    
    # –ò—Ç–æ–≥
    print("\n" + "=" * 80)
    if not issues:
        print("üéâ –°–ò–°–¢–ï–ú–ê –ü–†–û–®–õ–ê –ü–†–û–í–ï–†–ö–£ –¶–ï–õ–û–°–¢–ù–û–°–¢–ò!")
        print("–í—Å–µ —Ñ–∞–π–ª—ã –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É—é—Ç –∏ –Ω–µ –±—ã–ª–∏ –∏–∑–º–µ–Ω–µ–Ω—ã.")
        return True
    else:
        print(f"‚ö†Ô∏è  –û–ë–ù–ê–†–£–ñ–ï–ù–û –ü–†–û–ë–õ–ï–ú: {len(issues)}")
        print("–°–∏—Å—Ç–µ–º–∞ —Ç—Ä–µ–±—É–µ—Ç –≤–Ω–∏–º–∞–Ω–∏—è –ø–µ—Ä–µ–¥ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º.")
        return False

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    import argparse
    
    parser = argparse.ArgumentParser(
        description='–ü—Ä–æ–≤–µ—Ä–∫–∞ —Ü–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç–∏ LTO Backup System',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
–ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è:
  %(prog)s check          # –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Ü–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç—å —Å–∏—Å—Ç–µ–º—ã
  %(prog)s reference      # –°–æ–∑–¥–∞—Ç—å —ç—Ç–∞–ª–æ–Ω–Ω—ã–µ –∫–æ–Ω—Ç—Ä–æ–ª—å–Ω—ã–µ —Å—É–º–º—ã
  %(prog)s verify         # –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Å–∏—Å—Ç–µ–º—É –ø–æ —ç—Ç–∞–ª–æ–Ω—É
  %(prog)s compare A.json B.json  # –°—Ä–∞–≤–Ω–∏—Ç—å –¥–≤–∞ –æ—Ç—á–µ—Ç–∞
  %(prog)s full           # –ü–æ–ª–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ (check + reference + verify)
        """
    )
    
    parser.add_argument('command', 
                       choices=['check', 'reference', 'verify', 'compare', 'full', 'stats'],
                       help='–ö–æ–º–∞–Ω–¥–∞ –¥–ª—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è')
    
    parser.add_argument('args', nargs='*', help='–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –∞—Ä–≥—É–º–µ–Ω—Ç—ã')
    parser.add_argument('--dir', default='.', help='–ë–∞–∑–æ–≤—ã–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π —Å–∏—Å—Ç–µ–º—ã')
    
    args = parser.parse_args()
    
    try:
        if args.command == 'check':
            print("üîç –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ü–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç–∏ —Å–∏—Å—Ç–µ–º—ã...")
            report = generate_integrity_report(args.dir)
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫—Ä–∞—Ç–∫–∏–π –æ—Ç—á–µ—Ç
            summary_path = os.path.join(args.dir, 'integrity_summary.txt')
            with open(summary_path, 'w', encoding='utf-8') as f:
                f.write(f"–û—Ç—á–µ—Ç –æ —Ü–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç–∏ LTO Backup System\n")
                f.write(f"–í—Ä–µ–º—è: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                f.write(f"–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è: {os.path.abspath(args.dir)}\n")
                f.write(f"–í—Å–µ–≥–æ —Ñ–∞–π–ª–æ–≤: {len(report['files'])}\n")
                f.write(f"–ü—Ä–æ–±–ª–µ–º: {len(report['issues'])}\n\n")
                
                if report['issues']:
                    f.write("–ü—Ä–æ–±–ª–µ–º—ã:\n")
                    for issue in report['issues']:
                        f.write(f"- {issue}\n")
                else:
                    f.write("‚úÖ –í—Å–µ –ø—Ä–æ–≤–µ—Ä–∫–∏ –ø—Ä–æ–π–¥–µ–Ω—ã —É—Å–ø–µ—à–Ω–æ!\n")
            
            print(f"\nüìã –ö—Ä–∞—Ç–∫–∏–π –æ—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {summary_path}")
            
        elif args.command == 'reference':
            create_reference_checksums(args.dir)
            
        elif args.command == 'verify':
            success = verify_against_reference(args.dir)
            sys.exit(0 if success else 1)
            
        elif args.command == 'compare':
            if len(args.args) < 2:
                print("‚ùå –î–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –Ω—É–∂–Ω—ã –¥–≤–∞ —Ñ–∞–π–ª–∞ –æ—Ç—á–µ—Ç–æ–≤")
                sys.exit(1)
            compare_checksums(args.args[0], args.args[1])
            
        elif args.command == 'full':
            print("üîÑ –ü–û–õ–ù–ê–Ø –ü–†–û–í–ï–†–ö–ê –°–ò–°–¢–ï–ú–´")
            print("=" * 80)
            
            # 1. –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ü–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç–∏
            print("\nüîç –≠—Ç–∞–ø 1: –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ü–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç–∏...")
            generate_integrity_report(args.dir)
            
            # 2. –°–æ–∑–¥–∞–Ω–∏–µ —ç—Ç–∞–ª–æ–Ω–∞
            print("\nüèóÔ∏è –≠—Ç–∞–ø 2: –°–æ–∑–¥–∞–Ω–∏–µ —ç—Ç–∞–ª–æ–Ω–Ω—ã—Ö –∫–æ–Ω—Ç—Ä–æ–ª—å–Ω—ã—Ö —Å—É–º–º...")
            create_reference_checksums(args.dir)
            
            # 3. –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ —ç—Ç–∞–ª–æ–Ω—É
            print("\n‚úÖ –≠—Ç–∞–ø 3: –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ —ç—Ç–∞–ª–æ–Ω—É...")
            success = verify_against_reference(args.dir)
            
            if success:
                print("\nüéâ –ü–û–õ–ù–ê–Ø –ü–†–û–í–ï–†–ö–ê –ó–ê–í–ï–†–®–ï–ù–ê –£–°–ü–ï–®–ù–û!")
                print("–°–∏—Å—Ç–µ–º–∞ –≥–æ—Ç–æ–≤–∞ –∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é.")
            else:
                print("\n‚ö†Ô∏è  –ü–û–õ–ù–ê–Ø –ü–†–û–í–ï–†–ö–ê –í–´–Ø–í–ò–õ–ê –ü–†–û–ë–õ–ï–ú–´")
                print("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –∏—Å–ø—Ä–∞–≤—å—Ç–µ —É–∫–∞–∑–∞–Ω–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã.")
                sys.exit(1)
                
        elif args.command == 'stats':
            print("üìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê –°–ò–°–¢–ï–ú–´")
            print("=" * 80)
            
            checksums = get_file_checksums(args.dir)
            
            print(f"\nüìÅ –í—Å–µ–≥–æ —Ñ–∞–π–ª–æ–≤: {len(checksums)}")
            
            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Ç–∏–ø–∞–º —Ñ–∞–π–ª–æ–≤
            file_types = {}
            total_size = 0
            
            for file_path, info in checksums.items():
                ext = os.path.splitext(file_path)[1].lower()
                file_types[ext] = file_types.get(ext, 0) + 1
                total_size += info['size']
            
            print(f"üì¶ –û–±—â–∏–π —Ä–∞–∑–º–µ—Ä: {total_size / (1024*1024):.2f} MB")
            print("\nüìÑ –¢–∏–ø—ã —Ñ–∞–π–ª–æ–≤:")
            for ext, count in sorted(file_types.items()):
                print(f"   {ext or '–±–µ–∑ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è'}: {count} —Ñ–∞–π–ª–æ–≤")
            
            # –ö—Ä—É–ø–Ω–µ–π—à–∏–µ —Ñ–∞–π–ª—ã
            print("\nüèÜ –ö—Ä—É–ø–Ω–µ–π—à–∏–µ —Ñ–∞–π–ª—ã:")
            sorted_files = sorted(checksums.items(), 
                                key=lambda x: x[1]['size'], 
                                reverse=True)[:10]
            
            for i, (file_path, info) in enumerate(sorted_files, 1):
                size_mb = info['size'] / (1024*1024)
                print(f"   {i:2d}. {file_path[:60]:<60} {size_mb:6.2f} MB")
        
    except KeyboardInterrupt:
        print("\n\n‚èπÔ∏è  –ü—Ä–µ—Ä–≤–∞–Ω–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
        sys.exit(130)
    except Exception as e:
        print(f"\nüí• –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)

if __name__ == "__main__":
    main()
